{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act = nn.Tanh()\n",
    "        \n",
    "        #Feature exrtaction part of captioning\n",
    "        # input: 28x28x1\n",
    "        self.c1 = nn.Conv2d(1, 3, kernel_size=3, padding=1) # output: 28x28x3 SAME\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 14x14x3 \n",
    "\n",
    "        self.c2 = nn.Conv2d(3, 6, kernel_size=3, padding=1) # output: 14x14x6 SAME\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 7x7x6 \n",
    "        \n",
    "        self.c3 = nn.Conv2d(6, 12, kernel_size=3, padding=1) # output: 7x7x12 SAME\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=7*7*12, out_features=60) \n",
    "\n",
    "        #\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Conv Layer 1\n",
    "        x = self.c1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        #Conv Layer 2        \n",
    "        x = self.c2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        #Conv Layer 3\n",
    "        x = self.c3(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        #Flattening\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        #FC Layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        #FC Layer 2\n",
    "        x = self.fc2(x)       \n",
    "        \n",
    "        #Softmax\n",
    "        out = self.logSoftmax(x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch, \"ANTON\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_nr, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.to(device)\n",
    "            if (batch_nr%300 == 0):\n",
    "                print(\"batch_nr:\",batch_nr,\" loss:\",loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        writer.add_scalar(\"loss/train\", train_loss, epoch)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    writer.add_scalar(\"loss/val\", val_loss, epoch)\n",
    "    \n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "    \n",
    "    writer.flush()\n",
    "    return best_model\n",
    "\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    return test_loss, accuracy, conf_matrix"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
