{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Learning Machines\n",
    "## Exercise 5 - Convolutional ANN and Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The goal of this exercise is for you to get a better understanding of what convolution is, how it is leveraged to increase the usability and performance of neural networks. The exercise will also teach you about transfer learning and the differences between fine-tuning/feature extraction. \n",
    "\n",
    "## Literature\n",
    "This exercise will rely on the following sections in the [course book](https://www.deeplearningbook.org/).\n",
    "\n",
    "- Chapter 9\n",
    "    - Most of it\n",
    "- Chapter 7\n",
    "    - Section 7.4 - Dataset augmentation\n",
    "- Chapter 15\n",
    "    - Section 15.2 - Transfer learning\n",
    "    \n",
    "## Examination\n",
    "Epochs are predefined to be 30. Feel free to increase/decrease this number depending on the hardware that you are working with. Just make sure that you use the same hyperparameters on tasks 2, 3 and 4. **Make sure you have all examination requirements in order before presenting.**\n",
    "\n",
    "### Task 1\n",
    "1. Implementation of same convolution.\n",
    "2. The resulting image using 3 different filters.\n",
    "\n",
    "### Task 2\n",
    "1. The given network trained, validated and tested on the given dataset. Don't forget to make the train/validation/test split of the dataset. This can be achieved programmatically using https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split.\n",
    "2. Some type of regularization should be used. You should understand how the chosen regularization technique works.\n",
    "3. Report the training, validation and test accuracy. (Should beat randomly picking)\n",
    "4. Calculate and plot the multi-class [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "5. Add some augmentation techniques which fits well with the data. Does this increase or decrease the validation accuracy?\n",
    "\n",
    "### Task 3\n",
    "1. Fine-tune Resnet18 on the given dataset.\n",
    "2. Report the training, validation and test accuracy. (Should beat randomly picking)\n",
    "3. Calculate and plot the multi-class [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "4. Add some augmentation techniques which fits well with the data. Does this increase or decrease the validation accuracy?\n",
    "\n",
    "### Task 4\n",
    "1. Use Resnet18 as a feature extractor on the dataset.\n",
    "2. Report the training, validation and test accuracy. (Should beat randomly picking)\n",
    "3. Calculate and plot the multi-class [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "4. Add some augmentation techniques which fits well with the data. Does this increase or decrease the validation accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution in Neural Networks\n",
    "A convolutional neural network, CNN for short, is a type of ANN that consists of at least one convolutional layer. CNN's are often used where the input size may vary such as when we are dealing with image input. The architecture of CNNs was inspired by how the visual cortex functions in our brain.\n",
    "\n",
    "## Task 1: Implement convolution\n",
    "Implement 2d same convolution without using a built-in convolution function. This should function as described in [this blog post](https://jcbgamboa.github.io/2017/08/12/what-are-convolutions/). One of the great strengths of convolution is that it functions on any sized image, hence it is important that your implementation also does. Same convolution means that the dimensions of the output are the same as the dimensions of the input. This is achieved by padding the input.\n",
    "\n",
    "Once you have implemented a function that performs 2d convolution, use that to perform convolution over all channels in this image. Show the result using 3 different filters.\n",
    "\n",
    "To find the padding needed to get the input to be the same space as the output you can use the formula:\n",
    "\n",
    "$$ n_{out} = \\left \\lfloor\\frac{n_{in}+2p-k}{s} \\right \\rfloor+1 $$\n",
    "\n",
    "where $n_{out}$ is the number of output features, $n_{in}$ is the number of input features, $k$ is the kernel size, $p$ is the padding size and $s$ is the stride size. You can assume that the stride is always 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "padding = 0\n",
    "strides = 1\n",
    "# Our test, don't edit\n",
    "inp = np.array([[1,1,1,1],[1,1,2,1],[1,-3,-4,1],[1,1,1,1]])\n",
    "kernel = np.array([[0,1,0],[1,2,1],[0,1,0]]) # This is the second input of conv()\n",
    "\n",
    "kernel_flip = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "i_x, i_y = inp.shape\n",
    "k_x, k_y = kernel_flip.shape\n",
    "\n",
    "p_x = math.floor(((k_x-i_x)+strides*(i_x-1))/2)\n",
    "p_y = math.floor(((k_x-i_y)+strides*(i_y-1))/2)\n",
    "\n",
    "# p_x = (k_x - 1)//2\n",
    "# p_y = (k_x - 1)//2\n",
    "\n",
    "p_kernel = np.pad(kernel_flip, ((0, p_x), (0, p_y)), mode='constant')\n",
    "\n",
    "print(inp.shape, p_kernel.shape)\n",
    "\n",
    "print(p_kernel)\n",
    "\n",
    "ye = np.zeros((i_x, i_y))\n",
    "\n",
    "# Performing the convolution\n",
    "for x in range(i_x):\n",
    "    for y in range(i_y):\n",
    "        ye[x, y] = np.sum(i_x[x:x+p_kernel.shape[0], y:y+p_kernel.shape[1]] * p_kernel)\n",
    "\n",
    "print(ye)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 30]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Implement same convolution in the function below (kernel is a 2d numpy array an example of which can be found in the test)\n",
    "def conv(image, kernel, strides=1):\n",
    "    m, n = kernel.shape\n",
    "    if(m == n):\n",
    "        y, x = image.shape\n",
    "\n",
    "        padding_y = (m - 1) // 2\n",
    "        padding_x = (n - 1) // 2\n",
    "\n",
    "        padded_image = np.pad(image, ((padding_y, padding_y), (padding_x, padding_x)), mode='constant')\n",
    "\n",
    "        y = (y + 2 * padding_y - m) // strides + 1\n",
    "        x = (x + 2 * padding_x - m) // strides + 1\n",
    "\n",
    "        new_image = np.zeros((y,x))\n",
    "\n",
    "        for i in range(0, y * strides, strides):\n",
    "            for j in range(0, x * strides, strides):\n",
    "                new_image[i // strides][j // strides] = np.sum(padded_image[i:i+m, j:j+m]*kernel) \n",
    "    return new_image\n",
    "\n",
    "# Our test, don't edit\n",
    "inp = np.array([[1,1,1,1],[1,1,2,1],[1,-3,-4,1],[1,1,1,1]])\n",
    "kernel = np.array([[0,1,0],[1,2,1],[0,1,0]]) # This is the second input of conv()\n",
    "\n",
    "# If all are TRUE the convolution is implemented correctly\n",
    "ans = np.array([[4, 5, 6, 4], [5, 3, 3, 6], [1, -7, -7, 0], [4, 1, 0, 4]])\n",
    "print(conv(inp, kernel) == ans)\n",
    "\n",
    "f, axarr = plt.subplots(4,1)\n",
    "\n",
    "# How to load images using opencv\n",
    "image_path = r\"C:\\Users\\ludvi\\Documents\\Code\\nnlm\\ANN3\\ANN3_dataset\\101_ObjectCategories_2classes\\ant\\image_0001.jpg\" # add your file path here\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # gray scale so we dont have to deal with more than 1 channel\n",
    "\n",
    "# Define your 3 kernels\n",
    "kernel_1 = np.array([[-10,0,10],[-10,0,10],[-10,0,10]])\n",
    "kernel_2 = np.array([[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]])\n",
    "kernel_3 = np.array([[1,0,-1],[1,0,-1],[1,0,-1]])\n",
    "\n",
    "# Perform the convolution (might take a couple of seconds depending on the implementation)\n",
    "output1 = conv(image, kernel_1)\n",
    "output2 = conv(image, kernel_2)\n",
    "output3 = conv(image, kernel_3)\n",
    "\n",
    "# plot the loaded image and the 3 convoluted images\n",
    "axarr[0].imshow(image, cmap=\"gray\")\n",
    "axarr[1].imshow(output1, cmap=\"gray\")\n",
    "axarr[2].imshow(output2, cmap=\"gray\")\n",
    "axarr[3].imshow(output3, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "Computer vision (CV) is a task within the computer science field that aim is to extract high-level information from static images or video. Such high-level information can be, but is not limited to:\n",
    "* Object detection - Detect and classify objects within input images\n",
    "* Anomaly detection - Detect anomalies in the input images\n",
    "* Semantic segmentation - Classify each pixel in the input image into different classes\n",
    "* Object recognition - Classifying an entire image depending on what it contains\n",
    "\n",
    "CV has been studied for multiple decades where early solutions used handwritten feature extractors to extract information from the input. However, with the increase of computing power together with the rise of deep learning algorithms, the main method used to solve CV problems is convolutional neural networks.\n",
    "\n",
    "In this exercise, we will be taking a closer look at object recognition by first using a randomly initialized network and then utilizing transfer learning. **The dataset we will use for this exercise can be downloaded on canvas**. It is a subset of [this dataset](http://www.vision.caltech.edu/Image_Datasets/Caltech101/). Remember to split the data into separate training, validation and test set.\n",
    "\n",
    "## Task 2: Implement the missing code and train it on the given dataset.\n",
    "For task 2, implement the missing parts of the code below. The code should correctly train, validate and test the model. There are some comments guiding you through the process, however if something is unclear try to leverage the documentation for pytorch found [here](https://pytorch.org/docs/stable/index.html). You should also add some type of regularization into your model.\n",
    "\n",
    "Remember to check the examination requirements in the start of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import flatten, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = r\"C:\\Users\\ludvi\\Documents\\Code\\nnlm\\ANN3\\ANN3_dataset\\101_ObjectCategories_2classes\"\n",
    "BATCH_SIZE = 5\n",
    "SHUFFLE = True\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "AUG = True\n",
    "\n",
    "class NetW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetW, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # Applying filter ker\n",
    "        self.pool = nn.MaxPool2d(2, 2) # Pooling for reducing the computaional cost by \"downsampling\"\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_val_loss = 1000\n",
    "    best_model = model\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cuda()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "    return best_model\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    return test_loss, accuracy, conf_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(50),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "        # transforms.Resize(256),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "full_dataset = datasets.ImageFolder(root=DATA_DIR, transform=transforms.ToTensor())\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_indices, test_indices = train_test_split(range(len(full_dataset)), test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets for train, validation, and test sets with appropriate transformations\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# AUG = False\n",
    "AUG = True\n",
    "if AUG:\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    val_dataset.dataset.transform = val_test_transform\n",
    "    test_dataset.dataset.transform = val_test_transform\n",
    "    print(\"Images processed\")\n",
    "    \n",
    "# Create data loaders for train, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NetW().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, train_loader, val_loader, EPOCHS)\n",
    "# Test the model\n",
    "test_loss, test_accuracy, conf_matrix = test_model(trained_model, test_loader)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix, classes=['Anchor', 'Ant'], normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With AUG: \n",
    "Epoch 100/100, Train Loss: 0.2252, Val Loss: 0.6369\n",
    "Test Loss: 0.1739, Test Accuracy: 70.59%\n",
    "\n",
    "Without AUG: \n",
    "Epoch 100/100, Train Loss: 0.6858, Val Loss: 0.6951\n",
    "Test Loss: 0.1626, Test Accuracy: 52.94%\n",
    "\n",
    "The validation loss seems to increase when not augmentating the images. Why? I guess we introduce more variation with the cropping distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "Transfer learning refers to the practice to use a model which has already been pre-trained on a large dataset to be able to solve task $T_1$, replace the output layer or a few of the upper layers within this model and retrain the model on a smaller dataset to be able to solve task $T_2$. Formally this can be described as the following:\n",
    "\n",
    "__Def 1:__ Let $D_s$ be the source domain and $T_s$ be the corresponding source task. Let $D_t$ be the target domain and $T_t$ be the corresponding target task. Let $f_t$ be the predictive function for $T_s$. Thus transfer learning aims to improve the learning of $f_t$ in $D_t$ using the already learned knowledge in $D_s$ and $T_s$ where $D_s \\neq D_t$ and $T_s \\neq T_t$.\n",
    "\n",
    "The benefit from using transfer learning is that we can train an accurate computer vision model with relatively small amounts of data and computing resources compared to the costly pretraining process of the full convolutional neural network (a few days using multiple GPUs). \n",
    "\n",
    "## Fine-tuning and Feature extraction\n",
    "There are two main ideas when it comes to transfer learning, fine-tuning and feature extraction. When using fine-tuning we allow all weights to be changed during the training phase. However, when we use the pre-trained model as a feature extractor we instead freeze earlier layers of the model, which means that the weights in those layers will not be updated during the training phase and we only update the weights in the upper layers that we have replaced. \n",
    "\n",
    "This works because low-level information extracted from the input image is universal between tasks, examples of such information is edge detection, shape detection and pattern detection. This is what the early layers are optimized to do, where later layers extract more abstract features relevant for the task. \n",
    "\n",
    "Most of the pre-trained models in PyTorch are trained on [ImageNet](http://www.image-net.org/). \n",
    "\n",
    "In this exercise, we use ResNet18 as our model. You should make yourself familiar with the Resnet18 architecture using, for example, [the paper](https://arxiv.org/abs/1512.03385).\n",
    "\n",
    "## Task 3: Fine-tuning\n",
    "In task 3 you should fine-tune Resnet18 to the small dataset which is provided above. Some code has been given to you. Remember to re-use functions (such as trained_model) from task 2 to decrease the implementation time.\n",
    "\n",
    "Remember to check the examination requirements at the start of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune a model to the dataset\n",
    "# We use resnet18 as the model.\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "model_ft.to(device)\n",
    "# Do the things required for fine-tuning before training the model\n",
    "criterion_ft = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer_ft = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "# Train the model\n",
    "trained_model_ft = train_model(model_ft, criterion_ft, optimizer_ft, train_loader, val_loader, epochs)\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_accuracy, conf_matrix = test_model(trained_model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix, classes=['Anchor', 'Ant'], normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With AUG:\n",
    "\n",
    "Epoch 30/30, Train Loss: 11.7307, Val Loss: 20.4710\n",
    "Test Loss: 0.1479, Test Accuracy: 70.59%\n",
    "\n",
    "Without AUG:\n",
    "\n",
    "Epoch 30/30, Train Loss: 12.1505, Val Loss: 21.5382\n",
    "Test Loss: 0.1597, Test Accuracy: 52.94%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Feature extraction\n",
    "In task 4, you should use Resnet18 as a feature extractor. Similarly to task 3, some code has been provided. Remember to re-use as much code as you can. \n",
    "\n",
    "Once again, check the examination requirements so you don't forget to implement some required functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a predefined model as a feature extractor\n",
    "\n",
    "# We use resnet18 as the model.\n",
    "# Use a predefined model as a feature extractor\n",
    "model_fe = models.resnet18(pretrained=True)\n",
    "\n",
    "#Freeze parameters\n",
    "for param in model_fe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#Replace connected layer\n",
    "n_features = model_fe.fc.in_features\n",
    "model_fe.fc = (nn.Linear(n_features,2))\n",
    "\n",
    "model_fe.to(device)\n",
    "criterion_fe = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer_fe = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "# Train the model\n",
    "trained_model_fe = train_model(model_fe, criterion_fe, optimizer_fe, train_loader, val_loader, epochs)\n",
    "\n",
    "test_loss, test_accuracy, conf_matrix = test_model(trained_model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix, classes=['Anchor', 'Ant'], normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Aug:\n",
    "\n",
    "Epoch 30/30, Train Loss: 0.7837, Val Loss: 0.8365\n",
    "Test Loss: 0.1479, Test Accuracy: 70.59%\n",
    "\n",
    "Without:\n",
    "\n",
    "Epoch 30/30, Train Loss: 0.7420, Val Loss: 1.2240\n",
    "Test Loss: 0.1597, Test Accuracy: 52.94%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
